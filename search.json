[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Welcome to my project showcase. Click on a card to explore the full details.\n\n \n\nFriend\n\n\nA private voice chatbot using LLMs and TTS\n\n  \n\nNovAI\n\n\nAn interactive Novel Reader\n\n  \n\nNovAI QA\n\n\nA RAG-based approach to long-form literature analysis\n\n  \n\nComing Soon\n\n\nAnother upcoming project will be featured here"
  },
  {
    "objectID": "projects/novai.html",
    "href": "projects/novai.html",
    "title": "NovAI - Interactive Novel Reader",
    "section": "",
    "text": "NovAI is a full-stack web application that transforms online novels into an accessible listening experience. It combines web scraping technology with text-to-speech capabilities to allow users to both read and listen to novels with real-time paragraph highlighting.\nThe project features a React frontend with Material UI for the interface and a Python backend (FastAPI/Flask) that handles novel retrieval and processing. This separation of concerns allows for a responsive user experience while efficiently managing data processing on the server.\n\n\n\nNovAI Main Interface"
  },
  {
    "objectID": "projects/novai.html#overview",
    "href": "projects/novai.html#overview",
    "title": "NovAI - Interactive Novel Reader",
    "section": "",
    "text": "NovAI is a full-stack web application that transforms online novels into an accessible listening experience. It combines web scraping technology with text-to-speech capabilities to allow users to both read and listen to novels with real-time paragraph highlighting.\nThe project features a React frontend with Material UI for the interface and a Python backend (FastAPI/Flask) that handles novel retrieval and processing. This separation of concerns allows for a responsive user experience while efficiently managing data processing on the server.\n\n\n\nNovAI Main Interface"
  },
  {
    "objectID": "projects/novai.html#story-behind-the-project",
    "href": "projects/novai.html#story-behind-the-project",
    "title": "NovAI - Interactive Novel Reader",
    "section": "Story Behind the Project",
    "text": "Story Behind the Project\nAs an avid webnovel reader, I found myself manually copying and pasting chapters from websites into TTS tools just to listen to them. This process started with tab-switching and copy-pasting each chapter individually, then evolved into basic automation using AHK scripts. Eventually, I discovered web scraping, which let me batch-download chapters into a text file—speeding up the process dramatically.\nThat workflow worked, but it lacked elegance. I wanted something smoother, faster, and more accessible—so I built NovAI. With a full frontend and backend pipeline, chapter scraping became instant, and listening became seamless. What began as a personal solution to a repetitive task turned into a tool designed for comfort and efficiency."
  },
  {
    "objectID": "projects/novai.html#key-features",
    "href": "projects/novai.html#key-features",
    "title": "NovAI - Interactive Novel Reader",
    "section": "Key Features",
    "text": "Key Features\n\nNovel Content Retrieval: Search and fetch novels by keyword from online sources\nInteractive Text-to-Speech: Listen to novels with adjustable reading speed (0.5x to 2.5x)\nReal-time Visual Tracking: Paragraphs are highlighted as they’re being read\nFull Playback Controls: Play, pause, and stop functionality\nContent Management: Copy text to clipboard or download as TXT files\nResponsive Design: Optimized for various screen sizes\nContent Caching: Server-side caching for improved performance"
  },
  {
    "objectID": "projects/novai.html#tech-stack",
    "href": "projects/novai.html#tech-stack",
    "title": "NovAI - Interactive Novel Reader",
    "section": "Tech Stack",
    "text": "Tech Stack\n\nFrontend\n\nReact: Component-based UI development\nMaterial UI: Design system for consistent styling and theming\nTTS-Reader.com Engine: External text-to-speech service integration\nReact Hooks: State management and component lifecycle\nFetch API: Communication with backend services\n\n\n\nBackend\n\nFastAPI/Flask: API endpoints for content retrieval\naiohttp/BeautifulSoup4: Asynchronous web scraping\nSQLite: Content caching database\nasyncio: Asynchronous I/O framework\nPydantic: Data validation and settings management"
  },
  {
    "objectID": "projects/novai.html#architecture",
    "href": "projects/novai.html#architecture",
    "title": "NovAI - Interactive Novel Reader",
    "section": "Architecture",
    "text": "Architecture\n\n\n\nNovai Workflow\n\n\nThe application follows a client-server architecture with external services:\n\nClient (React): Handles user interface and visualization\nTTS-Reader.com Engine: Provides high-quality text-to-speech functionality\nServer (FastAPI/Flask): Manages novel discovery, content scraping, and text processing\nDatabase (SQLite): Caches scraped content to improve performance and reduce load on source websites"
  },
  {
    "objectID": "projects/novai.html#implementation-details",
    "href": "projects/novai.html#implementation-details",
    "title": "NovAI - Interactive Novel Reader",
    "section": "Implementation Details",
    "text": "Implementation Details\n\nFrontend Implementation\nThe React application provides an intuitive interface for novel reading with these core components:\n\nSearch Interface: Allows users to specify novel keywords and chapter parameters\nContent Display: Renders retrieved novel content with proper formatting\nTTS Engine Integration: Connects to browser’s native speech synthesis capabilities\nVisual Tracking System: Highlights paragraphs in real-time during playback\nResponsive Layout: Adapts to different screen sizes using Material UI Grid\n\n// Example of TTS implementation with TTS-Reader.com engine\nuseEffect(() =&gt; {\n  if (!window.wsGlobals || !window.wsGlobals.TtsEngine) {\n    console.error(\"TTS engine (wsGlobals.TtsEngine) is not available.\");\n    return;\n  }\n  \n  const tts = window.wsGlobals.TtsEngine;\n  ttsRef.current = tts;\n\n  tts.init({\n    onInit: (voices) =&gt; {\n      console.log(\"TTS Initialized.\");\n      tts.setRate(readingRate);\n      try {\n        tts.setVoiceByUri(\"urn:moz-tts:sapi:Microsoft Zira Desktop - English (United States)?en-US\");\n      } catch (e) {\n        console.warn(\"Could not set preferred voice, using default.\", e);\n      }\n    },\n    onStart: () =&gt; { console.log(\"Speech started for a segment.\"); },\n    onDone: handleSpeechDone,\n    onError: (err) =&gt; {\n      console.error(\"TTS Error:\", err);\n      setIsPlaying(false);\n      highlightParagraph(-1);\n    }\n  });\n  \n  // Cleanup function\n  return () =&gt; {\n    if (timerRef.current) clearTimeout(timerRef.current);\n    if (ttsRef.current) ttsRef.current.stop();\n    ttsRef.current = null;\n  };\n}, [textArray, readingRate, speakParagraph]);\n\n\nBackend Implementation\nThe Python backend handles the heavy lifting of content retrieval:\n\nNovel Search: Finds the correct novel based on user keywords\nContent Scraping: Extracts chapter content from web sources\nText Processing: Cleans and formats text for optimal reading/listening\nResponse Formatting: Returns structured data with both raw and formatted content\nCaching System: Stores previously retrieved content to improve performance\n\nasync def get_text(keyword, chapter, number):\n    async with aiohttp.ClientSession(headers=headers) as session:\n        urls, novel_title, novel_image = await get_urls(session, number, chapter, keyword)\n\n        tasks = [get_page_content(session, url) for url in urls]\n        texts = await asyncio.gather(*tasks)\n\n        text = '\\n'.join(texts)\n        text = preprocess(text)\n\n        text_array = [par.strip() for par in text.split(\"\\n\")]\n        text_formatted = \"\".join([f'&lt;p id=\"par{i}\"&gt;{par}&lt;/p&gt;' for i, par in enumerate(text_array)])\n\n        return {\n            'text': text,\n            \"title\": novel_title,\n            \"image\": novel_image,\n            \"formatted\": text_formatted,\n            \"array\": text_array\n        }"
  },
  {
    "objectID": "projects/novai.html#challenges-solutions",
    "href": "projects/novai.html#challenges-solutions",
    "title": "NovAI - Interactive Novel Reader",
    "section": "Challenges & Solutions",
    "text": "Challenges & Solutions\n\n\n\n\n\n\n\nChallenge\nSolution\n\n\n\n\nWeb Scraping Reliability\nImplemented robust error handling and fallback mechanisms\n\n\nTTS Performance\nOptimized text processing for better speech synthesis\n\n\nContent Variety\nDeveloped flexible parsing logic to handle different novel formats\n\n\nCross-Origin Limitations\nConfigured proper CORS handling on the backend\n\n\nReading Position Tracking\nCreated custom synchronization between text and speech"
  },
  {
    "objectID": "projects/novai.html#future-enhancements",
    "href": "projects/novai.html#future-enhancements",
    "title": "NovAI - Interactive Novel Reader",
    "section": "Future Enhancements",
    "text": "Future Enhancements\n\nUser Accounts: Save reading progress and preferences\nCustom Voice Support: Allow users to select different TTS voices\nOffline Support: Progressive Web App capabilities for offline reading\nAdvanced Search: Filter novels by genre, author, and rating\nMobile Applications: Native mobile versions for iOS and Android\nMulti-language Support: Expand beyond English content"
  },
  {
    "objectID": "projects/novai.html#lessons-learned",
    "href": "projects/novai.html#lessons-learned",
    "title": "NovAI - Interactive Novel Reader",
    "section": "Lessons Learned",
    "text": "Lessons Learned\nDeveloping NovAI provided valuable insights into:\n\nFull-Stack Integration: Balancing frontend and backend responsibilities\nWeb Speech API: Working with browser-based speech synthesis\nAsynchronous Processing: Managing concurrent operations in Python\nUser Experience Design: Creating an intuitive interface for audio content\nContent Processing: Transforming web content into accessible formats"
  },
  {
    "objectID": "projects/novai.html#code",
    "href": "projects/novai.html#code",
    "title": "NovAI - Interactive Novel Reader",
    "section": "Code",
    "text": "Code\n\nGitHub Repository – Frontend\nGitHub Repository – Backend"
  },
  {
    "objectID": "projects/friend-chatbot.html",
    "href": "projects/friend-chatbot.html",
    "title": "Friend – A Private Voice Chatbot",
    "section": "",
    "text": "Friend is a voice-enabled chatbot built as an experimental tool — or, as the name implies, a small “friend” you can talk to. It runs either using local LLMs or connects to Groq API if no local model is available.\nThe goal wasn’t to solve a business problem, but to test how far you can go combining speech input, language models, and TTS output with minimal tooling."
  },
  {
    "objectID": "projects/friend-chatbot.html#overview",
    "href": "projects/friend-chatbot.html#overview",
    "title": "Friend – A Private Voice Chatbot",
    "section": "",
    "text": "Friend is a voice-enabled chatbot built as an experimental tool — or, as the name implies, a small “friend” you can talk to. It runs either using local LLMs or connects to Groq API if no local model is available.\nThe goal wasn’t to solve a business problem, but to test how far you can go combining speech input, language models, and TTS output with minimal tooling."
  },
  {
    "objectID": "projects/friend-chatbot.html#how-it-works",
    "href": "projects/friend-chatbot.html#how-it-works",
    "title": "Friend – A Private Voice Chatbot",
    "section": "How It Works",
    "text": "How It Works\nThere are two ways to run the app: - A Jupyter Notebook interface - A Python CLI version\n\nUnder the hood:\n\n\n\nFriend Chatbot Workflow\n\n\n\nA while loop waits for user input\nIf no speech is detected after 2 seconds, it:\n\nRecords audio\nConverts it to text\nLogs the input into a simple text-based history\n\nThen:\n\nIf a local LLM is available, it runs the input there\nIf that fails, it sends the input to Groq API (external LLM)\n\nOnce a response is received:\n\nThe answer is added to the history\nIt’s spoken back to the user using TTS\nThe app then waits for the next message\n\n\n\n\nUX Detail\nThis is an experimental tool — built to test, learn, and better understand what it means to talk to machines in a more natural way. It wasn’t designed to scale, but to serve as a proof of concept for private, voice-based interaction with language models. It’s simple, and it works."
  },
  {
    "objectID": "projects/friend-chatbot.html#tech-stack",
    "href": "projects/friend-chatbot.html#tech-stack",
    "title": "Friend – A Private Voice Chatbot",
    "section": "Tech Stack",
    "text": "Tech Stack\n\nPython (CLI + Notebook)\nTTS + Speech Recognition\nLLMs (Groq API, Local Model fallback — Ollama)\nFile-based logging and history"
  },
  {
    "objectID": "projects/friend-chatbot.html#notes",
    "href": "projects/friend-chatbot.html#notes",
    "title": "Friend – A Private Voice Chatbot",
    "section": "Notes",
    "text": "Notes\n\n“The most interesting part was realizing how simple this is to build with the right tools. It’s not fancy — but it works. And it was fun to make.”"
  },
  {
    "objectID": "projects/friend-chatbot.html#code",
    "href": "projects/friend-chatbot.html#code",
    "title": "Friend – A Private Voice Chatbot",
    "section": "Code",
    "text": "Code\n\nGitHub Repository – Friend\n\n\nThis is an experimental tool — built to test, learn, and better understand what it means to talk to machines in a more natural way. It also serves as a proof of concept for private, voice-based interaction with language models. It’s simple, and it works."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I’m Mohamed El Ghali Benabou, a data scientist and applied mathematician with a deep interest in natural language processing, machine learning, and real-world applications of AI, especially in domains like ESG analytics, interactive AI systems, and intelligent search interfaces."
  },
  {
    "objectID": "about.html#academic-background",
    "href": "about.html#academic-background",
    "title": "About Me",
    "section": "Academic Background",
    "text": "Academic Background\n\nMaster’s in Statistics and Econometrics, Mohammed V University, Rabat (2021–2023)\nBachelor’s in Mathematics, Jean-François Champollion University, Albi, France (2014–2015)\nPreparatory Classes for Engineering Schools – Salmane Al-Farissi, Morocco"
  },
  {
    "objectID": "about.html#practical-experience",
    "href": "about.html#practical-experience",
    "title": "About Me",
    "section": "Practical Experience",
    "text": "Practical Experience\n\nFinal Project Intern at AIOX Labs – ToumAI Analytics\n\nBuilt a fine-tuned LLM to assess ESG impact of African companies\nScraped and processed multilingual data from media & social platforms\nApplied BERTopic, sentiment analysis, and visualization pipelines\n\nIntern at the Ministry of Maritime Fisheries – HR department\n(Earlier observational internship)"
  },
  {
    "objectID": "about.html#personal-projects",
    "href": "about.html#personal-projects",
    "title": "About Me",
    "section": "Personal Projects",
    "text": "Personal Projects\n\nRAG Chatbot for Google Reviews (2024 - Ongoing)\nLocal NLP assistant for review summarization using BERTopic + LLaMA 3.2 + FastAPI\nNOVAI – Novel/News Scraping + Recommender (2024 - Ongoing)\nFull-stack app with RAG + LangChain for custom search and reading experience, with TTS, keyword interaction, and smart suggestions\nTitanic ML Competition\nExploratory classification project using Random Forest to identify survival factors\n\nYou can find these projects and others on my GitHub."
  },
  {
    "objectID": "about.html#academic-projects",
    "href": "about.html#academic-projects",
    "title": "About Me",
    "section": "Academic Projects",
    "text": "Academic Projects\n\nUnsupervised Learning Algorithms – PCA, Clustering (R)\nSARIMA vs ML for Time Series Forecasting\nLife Expectancy vs Development Status\nMultivariate Studies with PCA, CA, MCA (SPSS)\n\nRead the reports here."
  },
  {
    "objectID": "about.html#skills",
    "href": "about.html#skills",
    "title": "About Me",
    "section": "Skills",
    "text": "Skills\nLanguages & Tools: Python, R, Scikit-Learn, Pandas, NumPy, PyTorch, TensorFlow, Keras, FastAPI, LangChain, SQL, Streamlit, PowerBI, SPSS, Git, Docker\nModeling & Theory: BERT, BERTopic, RAG, LSTM, CNN, HDBSCAN, CA/MCA, Econometrics\nWeb: FastAPI, Flask, aiohttp, BeautifulSoup, React (in progress)"
  },
  {
    "objectID": "about.html#languages",
    "href": "about.html#languages",
    "title": "About Me",
    "section": "Languages",
    "text": "Languages\n\nArabic – Native\n\nFrench – Bilingual\n\nEnglish – Fluent (TOEIC: 950/990)"
  },
  {
    "objectID": "about.html#personal-traits-interests",
    "href": "about.html#personal-traits-interests",
    "title": "About Me",
    "section": "Personal Traits & Interests",
    "text": "Personal Traits & Interests\n\nFlexible, creative, autonomous\nPassionate about reading (webnovels, manga), gaming (MOBA, RPGs, chess), and intense storytelling (dramas, thrillers)"
  },
  {
    "objectID": "about.html#contact",
    "href": "about.html#contact",
    "title": "About Me",
    "section": "Contact",
    "text": "Contact\n\nben-ghali@hotmail.com\n\nLinkedIn\n\nGitHub"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nMohamed El Ghali BENABOU\n",
    "section": "",
    "text": "Data Scientist & Machine Learning Engineer\n\n\n\nI specialize in transforming complex data into actionable insights through NLP, machine learning, and intelligent systems. From topic modeling to building RAG pipelines with LLMs, I create solutions that bridge theory and real-world impact.\n\n\n“Good ideas deserve solid execution — even if that starts small.”\n\n\nView Projects About Me\n\n\n\nCore Expertise\n\nNatural Language Processing\nMachine Learning\nRAG Systems\nData Analysis\n\n\n\nLet’s Connect\nI’m always interested in new challenges and opportunities. Feel free to look at my work and get in touch.\n\nGitHub\nLinkedIn\nEmail"
  },
  {
    "objectID": "projects/novai-qa.html",
    "href": "projects/novai-qa.html",
    "title": "Novai QA: Building a Spoiler-Free Novel Question Answering System",
    "section": "",
    "text": "Novai QA represents a novel approach to handling one of the most challenging problems in literature discussion: spoiler management. This Retrieval-Augmented Generation (RAG) system enables readers to ask questions about web novels while maintaining strict spoiler-free boundaries based on their current reading progress.\n\n\nLong-form web novels, particularly those from platforms like novelfull.com, often span thousands of chapters with complex character relationships and intricate plot developments. Readers frequently want to:\n\nClarify character relationships without spoiling future developments\nUnderstand complex world-building elements\nGet refreshers on past events without re-reading entire sections\nDiscuss plot points with confidence in spoiler safety\n\nTraditional approaches fail because they either: 1. Provide no spoiler protection 2. Require manual content curation 3. Cannot handle the scale of very long novels 4. Lack the contextual understanding needed for nuanced questions\n\n\n\nI developed a sophisticated RAG pipeline that combines:\n\nIntelligent Web Scraping for automated content acquisition\nHybrid Retrieval Systems mixing semantic and keyword-based search\nChapter-Based Spoiler Filtering for user progress awareness\nLocal LLM Integration for privacy and control\nContext-Aware Chunking for optimal information retrieval"
  },
  {
    "objectID": "projects/novai-qa.html#project-overview",
    "href": "projects/novai-qa.html#project-overview",
    "title": "Novai QA: Building a Spoiler-Free Novel Question Answering System",
    "section": "",
    "text": "Novai QA represents a novel approach to handling one of the most challenging problems in literature discussion: spoiler management. This Retrieval-Augmented Generation (RAG) system enables readers to ask questions about web novels while maintaining strict spoiler-free boundaries based on their current reading progress.\n\n\nLong-form web novels, particularly those from platforms like novelfull.com, often span thousands of chapters with complex character relationships and intricate plot developments. Readers frequently want to:\n\nClarify character relationships without spoiling future developments\nUnderstand complex world-building elements\nGet refreshers on past events without re-reading entire sections\nDiscuss plot points with confidence in spoiler safety\n\nTraditional approaches fail because they either: 1. Provide no spoiler protection 2. Require manual content curation 3. Cannot handle the scale of very long novels 4. Lack the contextual understanding needed for nuanced questions\n\n\n\nI developed a sophisticated RAG pipeline that combines:\n\nIntelligent Web Scraping for automated content acquisition\nHybrid Retrieval Systems mixing semantic and keyword-based search\nChapter-Based Spoiler Filtering for user progress awareness\nLocal LLM Integration for privacy and control\nContext-Aware Chunking for optimal information retrieval"
  },
  {
    "objectID": "projects/novai-qa.html#technical-architecture",
    "href": "projects/novai-qa.html#technical-architecture",
    "title": "Novai QA: Building a Spoiler-Free Novel Question Answering System",
    "section": "Technical Architecture",
    "text": "Technical Architecture\n\nSystem Design Philosophy\nThe architecture follows a modular pipeline design, where each component can be independently optimized and replaced:\n\n\n\nNovai QA Workflow\n\n\n\n\nCore Components Deep Dive\n\n1. Web Scraping Module (scraper.py)\nThe scraping system handles the complex task of extracting novel content from novelfull.com while managing:\nasync def refresh_database():\n    \"\"\"\n    Interactive novel discovery and batch content extraction\n    \"\"\"\n    # User-guided novel selection\n    keyword = input(\"Please enter a keyword to search for novels: \")\n    \n    # Cloudflare-aware scraping with fake headers\n    headers = header.generate()\n    connector = aiohttp.TCPConnector(limit=20)\n    \n    # Concurrent chapter extraction\n    tasks = [get_page_content(session, url) for url in chapter_urls]\n    chapter_contents = await asyncio.gather(*tasks)\nKey Features:\n- Cloudflare Protection Handling: Dynamic header generation and connection pooling\n- Concurrent Processing: Async operations for efficient batch downloads\n- Content Validation: Automatic detection and re-processing of failed downloads\n- Database Integration: Direct insertion with conflict resolution\n\n\n2. Intelligent Chunking System (chunker.py)\nThe chunking algorithm represents one of the most sophisticated aspects of the system:\ndef chunk_text(text, max_chunk_size=512, overlap=200, tokenizer=None):\n    \"\"\"\n    Adaptive chunking with context preservation\n    \"\"\"\n    paragraphs = segment_text(text, max_chunk_size, overlap, tokenizer)\n    \n    # Sophisticated overlap management\n    while current_chunk_size &lt;= size + overlap:\n        if j &gt;= 0 and current_chunk_size &lt;= max_chunk_size - paragraphs[j][1]:\n            current_chunk.insert(0, paragraphs[j][0])\n            current_chunk_size += paragraphs[j][1]\nAlgorithm Design:\n- Multi-Level Fallback: Paragraph → Sentence → Sub-sentence segmentation\n- Context-Aware Overlap: Intelligent boundary detection to preserve meaning\n- Token-Precise Sizing: Uses actual model tokenizer for accurate size calculation\n- Adaptive Processing: Handles varying content structures automatically\n\n\n3. Hybrid Retrieval System (retriever.py)\nThe retrieval system combines two complementary approaches:\nSemantic Search (ChromaDB):\ndef retrieve_context_chroma(query, novel_name, model, spoiler_threshold=None, k=5):\n    query_prompt = \"Represent this sentence for searching relevant passages: \"\n    query_vector = model.encode(query_prompt + query)\n    query_vector = query_vector / np.linalg.norm(query_vector)\n    \n    if spoiler_threshold:\n        results = collection.query(\n            query_embeddings=[query_vector.tolist()],\n            where={\"chapter_id\": {\"$lte\": spoiler_threshold}}\n        )\nKeyword Search (BM25):\ndef retrieve_context_bm25(query, novel_name, spoiler_threshold=None, k=5):\n    # Advanced preprocessing pipeline\n    query_tokens = preprocess(query)  # Lemmatization + POS tagging\n    bm25 = BM25Okapi(tokenized_docs)\n    scores = bm25.get_scores(query_tokens)\nFusion Strategy: The system combines results from both methods, leveraging the strengths of each:\n- Semantic search excels at conceptual queries and synonyms\n- BM25 captures exact name matches and specific terminology\n- Combined results provide comprehensive coverage\n\n\n4. Spoiler-Aware Filtering\nThe spoiler protection mechanism operates at the database query level for efficiency:\n# Chapter-based filtering in PostgreSQL\ncursor.execute(\"\"\"\n    SELECT chunks.id, chunks.chunk_content \n    FROM chunks \n    JOIN chapters ON chunks.chapter_id = chapters.id \n    WHERE chapters.novel_id = %s AND chapters.chapter_number &lt;= %s\n\"\"\", (novel_id, spoiler_threshold))\nThis approach ensures:\n- Database-Level Efficiency: Filtering happens during retrieval, not post-processing\n- Precise Control: Chapter-granular spoiler boundaries\n- User Agency: Optional spoiler protection based on user preference\n\n\n5. Response Generation (generator.py)\nThe generation system uses carefully crafted prompts to ensure grounded responses:\nsystem_prompt = \"\"\"You are a RAG system designed to answer questions about novels \nusing only the retrieved excerpts from the book. Your responses must be grounded \nin the supplied content, without guessing or adding external information.\"\"\"\nKey Features:\n- Strict Grounding: Responses limited to retrieved content only\n- Natural Language: No exposure of system mechanics to users\n- Thinking Chain Handling: Special processing for reasoning-based models\n- Graceful Uncertainty: Honest admission when information isn’t available"
  },
  {
    "objectID": "projects/novai-qa.html#implementation-challenges-solutions",
    "href": "projects/novai-qa.html#implementation-challenges-solutions",
    "title": "Novai QA: Building a Spoiler-Free Novel Question Answering System",
    "section": "Implementation Challenges & Solutions",
    "text": "Implementation Challenges & Solutions\n\nChallenge 1: Handling Very Long Novels\nProblem: Novels with 1000+ chapters generate tens of thousands of chunks, making retrieval computationally expensive.\nSolution:\n- Hierarchical Filtering: Database-level novel and chapter filtering before semantic search\n- Batch Processing: Optimized embedding generation with CUDA acceleration\n- Connection Pooling: Efficient database resource management\n\n\nChallenge 2: Context Preservation Across Chunks\nProblem: Critical information often spans paragraph boundaries, leading to fragmented context.\nSolution:\n# Intelligent overlap with context awareness\nj = i - 1\nwhile current_chunk_size &lt;= size + overlap:\n    if j &gt;= 0 and current_chunk_size &lt;= max_chunk_size - paragraphs[j][1]:\n        current_chunk.insert(0, paragraphs[j][0])  # Add previous context\nThis ensures each chunk contains sufficient context for standalone comprehension.\n\n\nChallenge 3: Character Name Variations\nProblem: Web novels often use multiple names/titles for characters, making retrieval inconsistent.\nSolution: Hybrid retrieval system where:\n- BM25 catches exact name matches and variations\n- Semantic search captures conceptual references\n- Combined results ensure comprehensive character coverage\n\n\nChallenge 4: Spoiler Boundary Precision\nProblem: Determining exact spoiler boundaries while maintaining retrieval efficiency.\nSolution: Chapter-level granularity with database-level filtering:\n- User Control: Explicit chapter specification\n- Conservative Approach: When uncertain, prioritize spoiler safety\n- Efficient Implementation: PostgreSQL query optimization"
  },
  {
    "objectID": "projects/novai-qa.html#performance-analysis",
    "href": "projects/novai-qa.html#performance-analysis",
    "title": "Novai QA: Building a Spoiler-Free Novel Question Answering System",
    "section": "Performance Analysis",
    "text": "Performance Analysis\n\nMetrics & Benchmarks\nChunking Performance:\n- Average novel (500 chapters): ~15-20 minutes processing time\n- Chunk generation: ~5,000-8,000 chunks per novel\n- Memory usage: ~2-4GB during processing peak\nRetrieval Speed:\n- Query processing: &lt;2 seconds average\n- Hybrid search: 10 chunks from each method (20 total)\n- Database queries: &lt;100ms with proper indexing\nResponse Quality:\n- Grounded accuracy: High adherence to source material\n- Contextual coherence: Strong performance due to overlap strategy\n- Spoiler safety: 100% when threshold properly set\n\n\nScalability Considerations\nCurrent Limits: - Single novel focus (by design)\n- GPU memory requirements for embeddings\n- PostgreSQL storage scaling with novel count\nOptimization Opportunities:\n- Caching frequently accessed chunks\n- Pre-computed embeddings and for common queries\n- Preprocessed text (lemmatized + POS tagged) for common queries\n- Distributed processing for multiple novels"
  },
  {
    "objectID": "projects/novai-qa.html#user-experience-design",
    "href": "projects/novai-qa.html#user-experience-design",
    "title": "Novai QA: Building a Spoiler-Free Novel Question Answering System",
    "section": "User Experience Design",
    "text": "User Experience Design\n\nInterface Philosophy\nThe Gradio interface prioritizes simplicity while providing essential controls:\nwith gr.Blocks(title=\"Novel Assistant Chatbot\", theme=gr.themes.Soft()) as demo:\n    novel_name = gr.Textbox(label=\"Novel Name\")\n    spoiler_threshold = gr.Number(label=\"Current Chapter (optional)\")\n    chatbot = gr.Chatbot(height=500, bubble_full_width=False)\n Figure: Novai QA interface upon launch, showcasing the minimalist design and spoiler control input.\nDesign Principles:\n- Minimal Cognitive Load: Essential controls only\n- Clear Spoiler Control: Obvious chapter input mechanism\n- Conversational Flow: Natural chat interface\n- Immediate Feedback: Real-time response generation\n\n\nInteraction Patterns\nTypical User Flow:\n1. Novel Selection: Enter novel name (exact match required)\n2. Progress Setting: Specify current chapter (optional but recommended)\n3. Natural Querying: Ask questions in conversational language\n4. Iterative Exploration: Follow up with related questions\nExample Interactions:\nUser: \"Who is the main character in Supreme Magus?\"\nSystem: \"Based on the story content, the main character is Lith...\"\n\nUser: \"What are his abilities?\"\nSystem: \"Lith demonstrates several key abilities including...\""
  },
  {
    "objectID": "projects/novai-qa.html#technical-stack-dependencies",
    "href": "projects/novai-qa.html#technical-stack-dependencies",
    "title": "Novai QA: Building a Spoiler-Free Novel Question Answering System",
    "section": "Technical Stack & Dependencies",
    "text": "Technical Stack & Dependencies\n\nCore Technologies\nBackend Framework:\n- Python 3.12+: Core development language\n- PostgreSQL: Primary data storage\n- ChromaDB: Vector similarity search\n- Ollama: Local LLM serving\nMachine Learning:\n- SentenceTransformers: Embedding generation\n- NLTK: Text preprocessing pipeline\n- rank-bm25: Keyword search implementation\nWeb Technologies:\n- Gradio: Interactive interface\n- aiohttp: Async web scraping\n- BeautifulSoup: HTML parsing\n\n\nHardware Requirements\nMinimum Specifications:\n- 16GB RAM (for embedding models)\n- CUDA-compatible GPU (recommended)\n- 10GB+ storage (varies by novel count)\n- Stable internet (for initial scraping)\nOptimal Configuration:\n- 32GB+ RAM\n- RTX 3080/4080 or equivalent\n- SSD storage for database performance\n- High-bandwidth internet connection"
  },
  {
    "objectID": "projects/novai-qa.html#development-retrospective",
    "href": "projects/novai-qa.html#development-retrospective",
    "title": "Novai QA: Building a Spoiler-Free Novel Question Answering System",
    "section": "Development Retrospective",
    "text": "Development Retrospective\n\nChunking Complexity Underestimated: Initially assumed to be a straightforward task, implementing overlap-based chunking proved significantly more complex. Developed a custom solution after facing multiple edge cases in context preservation.\n\nVector Store Exploration: Started with FAISS but abandoned it due to lack of native metadata filtering. Considered Milvus, but it was unavailable on Windows at the time of development.\n\nHybrid Retrieval Realization: BM25 was introduced to supplement semantic search but yielded poor results without lemmatization. Effective lemmatization required POS tagging, which added processing overhead.\n\nHardware Impact on Embeddings: Encoding ~1000 chapters with a GPU took ~40 minutes; estimated CPU time exceeded 8 hours. Highlighted the critical performance gap between CPU and CUDA-enabled hardware.\n\nDatabase Migration: Transitioned from SQLite to PostgreSQL for robust filtering and relational querying. However, ChromaDB continued using SQLite3 locally as its backend.\n\nOperational Logging: Introduced application-level logging to monitor scraping, chunking, and retrieval processes more systematically."
  },
  {
    "objectID": "projects/novai-qa.html#lessons-learned-future-directions",
    "href": "projects/novai-qa.html#lessons-learned-future-directions",
    "title": "Novai QA: Building a Spoiler-Free Novel Question Answering System",
    "section": "Lessons Learned & Future Directions",
    "text": "Lessons Learned & Future Directions\n\nKey Insights\n\nChunking Strategy Matters: The quality of text segmentation directly impacts retrieval quality\nHybrid Approaches Win: Combining semantic and keyword search provides superior coverage\nUser Agency is Critical: Spoiler control must be user-driven, not system-assumed\nLocal Processing Benefits: Privacy and control advantages outweigh cloud API convenience\n\n\n\nFuture Enhancements\nTechnical Improvements:\n- Advanced Reranking: LLM-based relevance scoring for retrieved content\n- Multi-Novel Support: Concurrent handling of multiple novel sources\n- Multi-Turn Conversation: Context-aware processing for follow-up queries\n- Conversation Memory: Persistent context across chat sessions\n- Auto-Update System: Periodic content synchronization with novel databases\nUser Experience:\n- Progressive Web App: Mobile-optimized interface\n- Reading Progress Integration: Automatic chapter tracking\n- Social Features: Shared discussions with spoiler awareness\n- Personalization: User preference learning and adaptation\nScalability & Performance:\n- Caching Layer: Redis integration for frequent queries\n- Distributed Processing: Multi-GPU embedding generation\n- API Development: REST endpoints for third-party integrations\n- Containerization: Docker deployment for easy scaling"
  },
  {
    "objectID": "projects/novai-qa.html#conclusion",
    "href": "projects/novai-qa.html#conclusion",
    "title": "Novai QA: Building a Spoiler-Free Novel Question Answering System",
    "section": "Conclusion",
    "text": "Conclusion\nThe Novai QA project demonstrates the practical application of modern NLP techniques to solve real-world problems in digital literature consumption. By combining web scraping, advanced text processing, hybrid retrieval systems, and local LLM generation, the system provides a unique solution to the spoiler management challenge.\nThe project showcases several key technical skills:\n- Full-Stack Development: From database design to web interface\n- NLP Pipeline Engineering: End-to-end text processing workflows\n- RAG System Architecture: Modern information retrieval and generation\n- Async Programming: Efficient concurrent processing\n- Database Optimization: Query performance and data modeling\nMost importantly, it addresses a genuine user need with a thoughtful, technically sound approach that prioritizes user control and content safety.\n\nThis project is part of my portfolio demonstrating expertise in NLP, RAG systems, and full-stack development. The complete codebase and documentation are available on GitHub."
  },
  {
    "objectID": "projects/placeholder1.html",
    "href": "projects/placeholder1.html",
    "title": "Example Project - RAG Chatbot for Google Reviews",
    "section": "",
    "text": "Google reviews are often noisy, redundant, and unstructured. Businesses need a fast way to understand what people are saying without reading thousands of comments.\n\n\n\nI created a local chatbot using a Retrieval-Augmented Generation (RAG) pipeline that allows a user to ask natural language questions about a business and get instant answers based on the review corpus.\n\nClustering reviews with BERTopic\nIndexing with FAISS\nUsing LLaMA 3.2 for natural language generation\nBuilt with FastAPI and served via a simple interface\n\n\n\n\n\nFast and relevant responses to complex user queries\nHigh user satisfaction in internal tests\nPotential for real-world deployment for businesses with large review volumes\n\n\n\n\nPython, FastAPI, LLaMA 3.2, BERTopic, SentenceTransformers, FAISS, Selenium, BeautifulSoup, React (WIP)\n\n\n\n\nGitHub Repository (placeholder link)\nDemo: Coming Soon"
  },
  {
    "objectID": "projects/placeholder1.html#problem",
    "href": "projects/placeholder1.html#problem",
    "title": "Example Project - RAG Chatbot for Google Reviews",
    "section": "",
    "text": "Google reviews are often noisy, redundant, and unstructured. Businesses need a fast way to understand what people are saying without reading thousands of comments."
  },
  {
    "objectID": "projects/placeholder1.html#approach",
    "href": "projects/placeholder1.html#approach",
    "title": "Example Project - RAG Chatbot for Google Reviews",
    "section": "",
    "text": "I created a local chatbot using a Retrieval-Augmented Generation (RAG) pipeline that allows a user to ask natural language questions about a business and get instant answers based on the review corpus.\n\nClustering reviews with BERTopic\nIndexing with FAISS\nUsing LLaMA 3.2 for natural language generation\nBuilt with FastAPI and served via a simple interface"
  },
  {
    "objectID": "projects/placeholder1.html#results",
    "href": "projects/placeholder1.html#results",
    "title": "Example Project - RAG Chatbot for Google Reviews",
    "section": "",
    "text": "Fast and relevant responses to complex user queries\nHigh user satisfaction in internal tests\nPotential for real-world deployment for businesses with large review volumes"
  },
  {
    "objectID": "projects/placeholder1.html#tech-stack",
    "href": "projects/placeholder1.html#tech-stack",
    "title": "Example Project - RAG Chatbot for Google Reviews",
    "section": "",
    "text": "Python, FastAPI, LLaMA 3.2, BERTopic, SentenceTransformers, FAISS, Selenium, BeautifulSoup, React (WIP)"
  },
  {
    "objectID": "projects/placeholder1.html#links",
    "href": "projects/placeholder1.html#links",
    "title": "Example Project - RAG Chatbot for Google Reviews",
    "section": "",
    "text": "GitHub Repository (placeholder link)\nDemo: Coming Soon"
  }
]